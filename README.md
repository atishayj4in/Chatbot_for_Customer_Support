# Chatbot for Customer Support
![Chatbot_for_Customer_Support.jpg](Chatbot_for_Customer_Support.jpg)
â—¦ Built an AI-powered customer support chatbot capable of answering real-world queries using Retrieval-Augmented Generation (RAG) and LLM integration.
<br>
â—¦ Designed and implemented an intent generation pipeline to convert 100K+ tweet-based support data into structured JSON formats.
<br>
â—¦ Leveraged FAISS and HuggingFace sentence embeddings to store and retrieve contextually relevant responses efficiently.
<br>
â—¦ Integrated Groqâ€™s LLaMA3-70B API via LangChain to generate polite, accurate, and grounded answers within a Streamlit-based chat interface.
<br>
â—¦ Achieved intelligent user interaction with styled avatars, session continuity, and confidence scoring, enhancing customer experience and support automation.
<br>

<h3 align="left">Simulation:</h3>
<p align="left">
<a href="https://github.com/atishayj4in/Dog_and_Cat_Classifier" target="blank"><img align="center" src="chatbot_ui.png" alt="Click here to view Chatbot Simulation Video" height="100%" width="100%" /></a>

# ğŸ¤– Chatbot Setup Guide

This guide walks you through the steps required to set up and run the chatbot locally using Streamlit and Groq LLM.

---

## ğŸ§° Prerequisites

- Python 3.8 or higher
- Virtual environment tool (`venv` or `virtualenv`)
- A Groq API key (get it from [Groq Console](https://console.groq.com/))

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

### 2ï¸âƒ£ Configure the Groq API Key

#### ğŸ” Step A: Add API Key to `.env`

Create a `.env` file in the root directory (if not already present) and add:

```
GROQ_API_KEY=your_groq_api_key_here
```

#### ğŸ›  Step B: Update `connect_memory_with_llm.py`

Open `connect_memory_with_llm.py` and locate the section with the comment:

```python
# Paste your API key here
```

Replace or add:

```python
groq_api_key = "your_groq_api_key_here"
```

---

### 3ï¸âƒ£ Add Your Data

Place your customer data CSV file in the `data/` directory.

> âš ï¸ **Note:** This chatbot has been tested with datasets up to **100,000 rows**.

Example:

```plaintext
project-root/
â””â”€â”€ data/
    â””â”€â”€ customer_data.csv
```

---

### 4ï¸âƒ£ Generate Intents

Run this script to generate the `intents.json` file from your dataset:

```bash
python intent_generation.py
```

---

### 5ï¸âƒ£ Build Vector Memory (FAISS)

Create vector embeddings and store them in a FAISS index:

```bash
python create_memory_for_llm.py
```

> â³ This step may take a few minutes depending on your dataset size.

---

### 6ï¸âƒ£ Launch the Chatbot

Use Streamlit to run the chatbot:

```bash
streamlit run chatbot.py
```

Open your browser and visit:

```
http://localhost:8501
```

---

## âœ… You're All Set!

Your chatbot is now running locally!  
You can now interact, test, and enhance it as needed.

---

## ğŸ“ Project Structure Overview

```plaintext
â”œâ”€â”€ data/
â”‚   â””â”€â”€ chatbot_data.csv
â”‚   â””â”€â”€ intents.json
â”‚
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ db_faiss/
â”‚       â””â”€â”€ index.faiss
â”‚       â””â”€â”€ index.pkl
â”‚
â”œâ”€â”€ venv/                          # Virtual environment folder
â”‚
â”œâ”€â”€ .env                           # Environment file with Groq API key
â”œâ”€â”€ chatbot.py                     # Main chatbot launcher (Streamlit)
â”œâ”€â”€ connect_memory_with_llm.py     # Connects LLM with vector DB
â”œâ”€â”€ create_memory_for_llm.py       # Script to generate vector memory
â”œâ”€â”€ intent_generation.py           # Generates intents.json from CSV
â”œâ”€â”€ requirements.txt               # Python dependencies
```
